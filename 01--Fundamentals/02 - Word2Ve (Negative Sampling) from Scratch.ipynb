{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Word2Vec (Negative Sampling)\n",
        "\n",
        "Let's work on negative-sampling based implementation of word2vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Define some very simple data for understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\",\n",
        "                 \"dog cat animal\", \"cat animal dog\", \"cat dog animal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['apple', 'banana', 'fruit'],\n",
              " ['banana', 'apple', 'fruit'],\n",
              " ['banana', 'fruit', 'apple'],\n",
              " ['dog', 'cat', 'animal'],\n",
              " ['cat', 'animal', 'dog'],\n",
              " ['cat', 'dog', 'animal']]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = [sent.split(\" \") for sent in corpus]\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'animal', 'banana', 'fruit', 'dog', 'cat']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get word sequences and unique words\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocab = list(set(flatten(corpus)))\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'apple': 0, 'animal': 1, 'banana': 2, 'fruit': 3, 'dog': 4, 'cat': 5}\n"
          ]
        }
      ],
      "source": [
        "#numericalization\n",
        "word2index = {w: i for i, w in enumerate(vocab)}\n",
        "print(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "#vocab size\n",
        "voc_size = len(vocab)\n",
        "print(voc_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#append UNK\n",
        "vocab.append('<UNK>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'animal', 'banana', 'fruit', 'dog', 'cat', '<UNK>']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2index['<UNK>'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#just in case we need to use\n",
        "index2word = {v:k for k, v in word2index.items()} "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Prepare train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'fruit']\n",
            "['banana', 'apple', 'fruit']\n",
            "['banana', 'fruit', 'apple']\n",
            "['dog', 'cat', 'animal']\n",
            "['cat', 'animal', 'dog']\n",
            "['cat', 'dog', 'animal']\n"
          ]
        }
      ],
      "source": [
        "for c in corpus:\n",
        "    print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def random_batch(batch_size, word_sequence):\n",
        "    \n",
        "    # Make skip gram of one size window\n",
        "    skip_grams = []\n",
        "    # loop each word sequence\n",
        "    # we starts from 1 because 0 has no context\n",
        "    # we stop at second last for the same reason\n",
        "    for sent in corpus:\n",
        "        for i in range(1, len(sent) - 1):\n",
        "            target = word2index[sent[i]]\n",
        "            context = [word2index[sent[i - 1]], word2index[sent[i + 1]]]\n",
        "            for w in context:\n",
        "                skip_grams.append([target, w])\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_index = np.random.choice(range(len(skip_grams)), batch_size, replace=False) #randomly pick without replacement\n",
        "        \n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams[i][0]])  # target, e.g., 2\n",
        "        random_labels.append([skip_grams[i][1]])  # context word, e.g., 3\n",
        "            \n",
        "    return np.array(random_inputs), np.array(random_labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  [[1]\n",
            " [5]]\n",
            "Target:  [[5]\n",
            " [1]]\n"
          ]
        }
      ],
      "source": [
        "#testing the method\n",
        "batch_size = 2 # mini-batch size\n",
        "input_batch, target_batch = random_batch(batch_size, corpus)\n",
        "\n",
        "print(\"Input: \",  input_batch)\n",
        "print(\"Target: \", target_batch)\n",
        "\n",
        "#we will convert them to tensor during training, so don't worry..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((2, 1), (2, 1))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_batch.shape, target_batch.shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Negative Sampling"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unigram distribution\n",
        "\n",
        "$$P(w)=U(w)^{3/4}/Z$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "Z = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({'apple': 3, 'banana': 3, 'fruit': 3, 'dog': 3, 'cat': 3, 'animal': 3})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "word_count = Counter(flatten(corpus))\n",
        "num_total_words = sum([c for w, c in word_count.items()])\n",
        "print(word_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_count[',']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_total_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "unigram_table = []\n",
        "\n",
        "for vo in vocab:\n",
        "    unigram_table.extend([vo] * int(((word_count[vo]/num_total_words)**0.75)/Z))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'apple': 260,\n",
              "         'animal': 260,\n",
              "         'banana': 260,\n",
              "         'fruit': 260,\n",
              "         'dog': 260,\n",
              "         'cat': 260})"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Counter(unigram_table)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Negative Sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def prepare_sequence(seq, word2index):\n",
        "    idxs = list(map(lambda w: word2index[w] if word2index.get(w) is not None else word2index[\"<UNK>\"], seq))\n",
        "    return torch.LongTensor(idxs)\n",
        "\n",
        "def negative_sampling(targets, unigram_table, k):\n",
        "    batch_size = targets.size(0)\n",
        "    neg_samples = []\n",
        "    for i in range(batch_size):\n",
        "        nsample = []\n",
        "        target_index = targets[i].item()\n",
        "        while len(nsample) < k: # num of sampling\n",
        "            neg = random.choice(unigram_table)\n",
        "            if word2index[neg] == target_index:\n",
        "                continue\n",
        "            nsample.append(neg)\n",
        "        neg_samples.append(prepare_sequence(nsample, word2index).view(1, -1))\n",
        "    return torch.cat(neg_samples)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the negative sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_batch  = torch.Tensor(input_batch)\n",
        "target_batch = torch.LongTensor(target_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 1])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2],\n",
              "        [3]])"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[4, 4, 2],\n",
              "        [4, 3, 3]])"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "num_neg = 3\n",
        "negative_sampling(target_batch, unigram_table, num_neg)\n",
        "\n",
        "#{'grapes': 0, 'apple': 1, 'animal': 2, 'cat': 3, 'ice': 4, 'orange': 5, 'dog': 6, 'monkey': 7, 'conda': 8, 'fruit': 9, 'banana': 10}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_batch[1]\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model\n",
        "\n",
        "$$\\mathbf{J}_{\\text{neg-sample}}(\\mathbf{v}_c,o,\\mathbf{U})=-\\log(\\sigma(\\mathbf{u}_o^T\\mathbf{v}_c))-\\sum_{k=1}^K\\log(\\sigma(-\\mathbf{u}_k^T\\mathbf{v}_c))$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SkipgramNegSampling(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, emb_size):\n",
        "        super(SkipgramNegSampling, self).__init__()\n",
        "        self.embedding_v = nn.Embedding(vocab_size, emb_size) # center embedding\n",
        "        self.embedding_u = nn.Embedding(vocab_size, emb_size) # out embedding\n",
        "        self.logsigmoid = nn.LogSigmoid()\n",
        "                    \n",
        "    def forward(self, center_words, target_words, negative_words):\n",
        "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
        "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
        "        neg_embeds    = -self.embedding_u(negative_words) # [batch_size, num_neg, emb_size]\n",
        "        \n",
        "        positive_score = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
        "        \n",
        "        negative_score = neg_embeds.bmm(center_embeds.transpose(1, 2))\n",
        "        #[batch_size, k, emb_size] @ [batch_size, emb_size, 1] = [batch_size, k, 1]\n",
        "        \n",
        "        loss = self.logsigmoid(positive_score) + torch.sum(self.logsigmoid(negative_score), 1)\n",
        "                \n",
        "        return -torch.mean(loss)\n",
        "    \n",
        "    def prediction(self, inputs):\n",
        "        embeds = self.embedding_v(inputs)\n",
        "        \n",
        "        return embeds"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size     = 2 # mini-batch size\n",
        "embedding_size = 2 #so we can later plot\n",
        "model          = SkipgramNegSampling(voc_size, embedding_size)\n",
        "num_neg        = 10 # num of negative sampling\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000 | cost: 7.623516 | time: 0m 0s\n",
            "Epoch: 2000 | cost: 3.423092 | time: 0m 0s\n",
            "Epoch: 3000 | cost: 3.782731 | time: 0m 0s\n",
            "Epoch: 4000 | cost: 2.865985 | time: 0m 0s\n",
            "Epoch: 5000 | cost: 2.166276 | time: 0m 0s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    input_batch, target_batch = random_batch(batch_size, corpus)\n",
        "    \n",
        "    #input_batch: [batch_size, 1]\n",
        "    input_batch = torch.LongTensor(input_batch)\n",
        "    \n",
        "    #target_batch: [batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch)\n",
        "    \n",
        "    #negs_batch:   [batch_size, num_neg]\n",
        "    negs_batch = negative_sampling(target_batch, unigram_table, num_neg)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "        \n",
        "    loss = model(input_batch, target_batch, negs_batch)\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Plotting the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'animal', 'banana', 'fruit', 'dog', 'cat', '<UNK>']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#list of vocabs\n",
        "vocab[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "word = vocab[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#numericalization\n",
        "id = word2index[word]\n",
        "id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_tensor = torch.LongTensor([id])\n",
        "id_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1.7931, 0.9425]], grad_fn=<EmbeddingBackward0>),\n",
              " tensor([[-1.9231, -0.7726]], grad_fn=<EmbeddingBackward0>))"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get the embedding by averaging\n",
        "v_embed = model.embedding_v(id_tensor)\n",
        "u_embed = model.embedding_u(id_tensor)\n",
        "\n",
        "v_embed, u_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.0849, grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#average to get the word embedding\n",
        "word_embed = (v_embed + u_embed) / 2\n",
        "word_embed[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's write a function to get embedding given a word\n",
        "def get_embed(word):\n",
        "    id_tensor = torch.LongTensor([word2index[word]])\n",
        "    v_embed = model.embedding_v(id_tensor)\n",
        "    u_embed = model.embedding_u(id_tensor) \n",
        "    word_embed = (v_embed + u_embed) / 2 \n",
        "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "for i, word in enumerate(vocab[:20]): #loop each unique vocab\n",
        "    x, y = get_embed(word)\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Cosine similarity\n",
        "\n",
        "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
        "\n",
        "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
        "\n",
        "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'animal', 'banana', 'fruit', 'dog', 'cat', '<UNK>']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's try similarity between first and second, and second and third\n",
        "cat          = get_embed('cat')\n",
        "fruit        = get_embed('fruit')\n",
        "animal       = get_embed('animal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  -0.7869969573403314\n",
            "cat vs. animal:  0.96700861606579\n",
            "cat vs. cat:  1.0000000000000002\n"
          ]
        }
      ],
      "source": [
        "#numpy version\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim\n",
        "    \n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  -0.7869969573403313\n",
            "cat vs. animal:  0.9670086160657899\n",
            "cat vs. cat:  1.0\n"
          ]
        }
      ],
      "source": [
        "#scipy version\n",
        "from scipy import spatial\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = 1 - spatial.distance.cosine(a, b)  #distance = 1 - similarlity, because scipy only gives distance\n",
        "    return cos_sim\n",
        "\n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}

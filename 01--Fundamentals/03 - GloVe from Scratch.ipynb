{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GloVE\n",
        "\n",
        "Let's work on implementation of GloVE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Define some very simple data for understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = [\"apple banana fruit\", \"banana apple fruit\", \"banana fruit apple\",\n",
        "                 \"dog cat animal\", \"cat animal dog\", \"cat dog animal\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['apple', 'banana', 'fruit'],\n",
              " ['banana', 'apple', 'fruit'],\n",
              " ['banana', 'fruit', 'apple'],\n",
              " ['dog', 'cat', 'animal'],\n",
              " ['cat', 'animal', 'dog'],\n",
              " ['cat', 'dog', 'animal']]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus = [sent.split(\" \") for sent in corpus]\n",
        "corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'cat', 'fruit', 'dog', 'banana', 'animal']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get word sequences and unique words\n",
        "flatten = lambda l: [item for sublist in l for item in sublist]\n",
        "vocab = list(set(flatten(corpus)))\n",
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'apple': 0, 'cat': 1, 'fruit': 2, 'dog': 3, 'banana': 4, 'animal': 5}\n"
          ]
        }
      ],
      "source": [
        "#numericalization\n",
        "word2index = {w: i for i, w in enumerate(vocab)}\n",
        "print(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n"
          ]
        }
      ],
      "source": [
        "#vocab size\n",
        "voc_size = len(vocab)\n",
        "print(voc_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#append UNK\n",
        "vocab.append('<UNK>')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'cat', 'fruit', 'dog', 'banana', 'animal', '<UNK>']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2index['<UNK>'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "#just in case we need to use\n",
        "index2word = {v:k for k, v in word2index.items()} "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Build Co-occurence Matrix X"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here, we need to count the co-occurence of two words given some window size.  We gonna use window size of 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "collapsed": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({'apple': 3, 'banana': 3, 'fruit': 3, 'dog': 3, 'cat': 3, 'animal': 3})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "X_i = Counter(flatten(corpus)) # X_i\n",
        "X_i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('banana', 'apple'),\n",
              " ('banana', 'fruit'),\n",
              " ('apple', 'banana'),\n",
              " ('apple', 'fruit'),\n",
              " ('fruit', 'banana'),\n",
              " ('fruit', 'apple'),\n",
              " ('cat', 'dog'),\n",
              " ('cat', 'animal'),\n",
              " ('animal', 'cat'),\n",
              " ('animal', 'dog'),\n",
              " ('dog', 'cat'),\n",
              " ('dog', 'animal')]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make skip gram of one size window\n",
        "skip_grams = []\n",
        "# loop each word sequence\n",
        "# we starts from 1 because 0 has no context\n",
        "# we stop at second last for the same reason\n",
        "for sent in corpus:\n",
        "    for i in range(1, len(sent) - 1):\n",
        "        target = sent[i]\n",
        "        context = [sent[i - 1], sent[i + 1]]\n",
        "        for w in context:\n",
        "            skip_grams.append((target, w))\n",
        "\n",
        "skip_grams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "collapsed": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({('banana', 'apple'): 1,\n",
              "         ('banana', 'fruit'): 1,\n",
              "         ('apple', 'banana'): 1,\n",
              "         ('apple', 'fruit'): 1,\n",
              "         ('fruit', 'banana'): 1,\n",
              "         ('fruit', 'apple'): 1,\n",
              "         ('cat', 'dog'): 1,\n",
              "         ('cat', 'animal'): 1,\n",
              "         ('animal', 'cat'): 1,\n",
              "         ('animal', 'dog'): 1,\n",
              "         ('dog', 'cat'): 1,\n",
              "         ('dog', 'animal'): 1})"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_ik_skipgram = Counter(skip_grams) # Co-occurece in window size 1\n",
        "X_ik_skipgram"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Weighting function\n",
        "\n",
        "GloVe includes a weighting function to scale down too frequent words.\n",
        "\n",
        "<img src = \"figures/glove_weighting_func.png\" width=400>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#simply a normalized function...don't worry too much\n",
        "def weighting(w_i, w_j, X_ik):\n",
        "        \n",
        "    #check whether the co-occurrences exist between these two words\n",
        "    try:\n",
        "        x_ij = X_ik[(w_i, w_j)]\n",
        "    except:\n",
        "        x_ij = 1  #if does not exist, set it to 1\n",
        "                \n",
        "    x_max = 100 #100 # fixed in paper  #cannot exceed 100 counts\n",
        "    alpha = 0.75\n",
        "    \n",
        "    #if co-occurrence does not exceed 100, scale it based on some alpha\n",
        "    if x_ij < x_max:\n",
        "        result = (x_ij/x_max)**alpha  #scale it\n",
        "    else:\n",
        "        result = 1  #if is greater than max, set it to 1 maximum\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_ik={('apple', 'fruit'): 2, ('fruit', 'apple'): 2, ('apple', 'banana'): 2, ('banana', 'apple'): 2, ('cat', 'dog'): 2, ('dog', 'cat'): 2, ('cat', 'animal'): 2, ('animal', 'cat'): 2, ('fruit', 'banana'): 2, ('banana', 'fruit'): 2, ('dog', 'animal'): 2, ('animal', 'dog'): 2}\n",
            "weighting_dic={('apple', 'apple'): 0.03162277660168379, ('apple', 'cat'): 0.03162277660168379, ('cat', 'apple'): 0.03162277660168379, ('apple', 'fruit'): 0.053182958969449884, ('fruit', 'apple'): 0.053182958969449884, ('apple', 'dog'): 0.03162277660168379, ('dog', 'apple'): 0.03162277660168379, ('apple', 'banana'): 0.053182958969449884, ('banana', 'apple'): 0.053182958969449884, ('apple', 'animal'): 0.03162277660168379, ('animal', 'apple'): 0.03162277660168379, ('apple', '<UNK>'): 0.03162277660168379, ('<UNK>', 'apple'): 0.03162277660168379, ('cat', 'cat'): 0.03162277660168379, ('cat', 'fruit'): 0.03162277660168379, ('fruit', 'cat'): 0.03162277660168379, ('cat', 'dog'): 0.053182958969449884, ('dog', 'cat'): 0.053182958969449884, ('cat', 'banana'): 0.03162277660168379, ('banana', 'cat'): 0.03162277660168379, ('cat', 'animal'): 0.053182958969449884, ('animal', 'cat'): 0.053182958969449884, ('cat', '<UNK>'): 0.03162277660168379, ('<UNK>', 'cat'): 0.03162277660168379, ('fruit', 'fruit'): 0.03162277660168379, ('fruit', 'dog'): 0.03162277660168379, ('dog', 'fruit'): 0.03162277660168379, ('fruit', 'banana'): 0.053182958969449884, ('banana', 'fruit'): 0.053182958969449884, ('fruit', 'animal'): 0.03162277660168379, ('animal', 'fruit'): 0.03162277660168379, ('fruit', '<UNK>'): 0.03162277660168379, ('<UNK>', 'fruit'): 0.03162277660168379, ('dog', 'dog'): 0.03162277660168379, ('dog', 'banana'): 0.03162277660168379, ('banana', 'dog'): 0.03162277660168379, ('dog', 'animal'): 0.053182958969449884, ('animal', 'dog'): 0.053182958969449884, ('dog', '<UNK>'): 0.03162277660168379, ('<UNK>', 'dog'): 0.03162277660168379, ('banana', 'banana'): 0.03162277660168379, ('banana', 'animal'): 0.03162277660168379, ('animal', 'banana'): 0.03162277660168379, ('banana', '<UNK>'): 0.03162277660168379, ('<UNK>', 'banana'): 0.03162277660168379, ('animal', 'animal'): 0.03162277660168379, ('animal', '<UNK>'): 0.03162277660168379, ('<UNK>', 'animal'): 0.03162277660168379, ('<UNK>', '<UNK>'): 0.03162277660168379}\n"
          ]
        }
      ],
      "source": [
        "from itertools import combinations_with_replacement\n",
        "\n",
        "X_ik = {}  #for keeping the co-occurences\n",
        "weighting_dic = {} #scaling the percentage of sampling\n",
        "\n",
        "for bigram in combinations_with_replacement(vocab, 2):\n",
        "    if X_ik_skipgram.get(bigram) is not None:  #matches \n",
        "        co_occer = X_ik_skipgram[bigram]  #get the count from what we already counted\n",
        "        X_ik[bigram] = co_occer + 1 # + 1 for stability issue\n",
        "        X_ik[(bigram[1],bigram[0])] = co_occer+1   #count also for the opposite\n",
        "    else:\n",
        "        pass\n",
        "        \n",
        "    weighting_dic[bigram] = weighting(bigram[0], bigram[1], X_ik)\n",
        "    weighting_dic[(bigram[1], bigram[0])] = weighting(bigram[1], bigram[0], X_ik)\n",
        "\n",
        "print(f\"{X_ik=}\")\n",
        "print(f\"{weighting_dic=}\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Prepare train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple', 'banana', 'fruit']\n",
            "['banana', 'apple', 'fruit']\n",
            "['banana', 'fruit', 'apple']\n",
            "['dog', 'cat', 'animal']\n",
            "['cat', 'animal', 'dog']\n",
            "['cat', 'dog', 'animal']\n"
          ]
        }
      ],
      "source": [
        "for c in corpus:\n",
        "    print(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def random_batch(batch_size, word_sequence, skip_grams, X_ik, weighting_dic):\n",
        "    \n",
        "    #convert to id since our skip_grams is word, not yet id\n",
        "    skip_grams_id = [(word2index[skip_gram[0]], word2index[skip_gram[1]]) for skip_gram in skip_grams]\n",
        "    \n",
        "    random_inputs = []\n",
        "    random_labels = []\n",
        "    random_coocs  = []\n",
        "    random_weightings = []\n",
        "    random_index = np.random.choice(range(len(skip_grams_id)), batch_size, replace=False) #randomly pick without replacement\n",
        "        \n",
        "    for i in random_index:\n",
        "        random_inputs.append([skip_grams_id[i][0]])  # target, e.g., 2\n",
        "        random_labels.append([skip_grams_id[i][1]])  # context word, e.g., 3\n",
        "        \n",
        "        #get cooc\n",
        "        pair = skip_grams[i]\n",
        "        try:\n",
        "            cooc = X_ik[pair]\n",
        "        except:\n",
        "            cooc = 1\n",
        "        random_coocs.append([math.log(cooc)])\n",
        "        \n",
        "        #get weighting\n",
        "        weighting = weighting_dic[pair]\n",
        "        random_weightings.append([weighting])\n",
        "                    \n",
        "    return np.array(random_inputs), np.array(random_labels), np.array(random_coocs), np.array(random_weightings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:  [[5]\n",
            " [3]]\n",
            "Target:  [[3]\n",
            " [5]]\n",
            "Cooc:  [[0.69314718]\n",
            " [0.69314718]]\n",
            "Weighting:  [[0.05318296]\n",
            " [0.05318296]]\n"
          ]
        }
      ],
      "source": [
        "#testing the method\n",
        "batch_size = 2 # mini-batch size\n",
        "input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "\n",
        "print(\"Input: \", input_batch)\n",
        "print(\"Target: \", target_batch)\n",
        "print(\"Cooc: \", cooc_batch)\n",
        "print(\"Weighting: \", weighting_batch)\n",
        "\n",
        "#we will convert them to tensor during training, so don't worry..."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model\n",
        "\n",
        "<img src =\"figures/glove.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GloVe(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size,embed_size):\n",
        "        super(GloVe,self).__init__()\n",
        "        self.embedding_v = nn.Embedding(vocab_size, embed_size) # center embedding\n",
        "        self.embedding_u = nn.Embedding(vocab_size, embed_size) # out embedding\n",
        "        \n",
        "        self.v_bias = nn.Embedding(vocab_size, 1)\n",
        "        self.u_bias = nn.Embedding(vocab_size, 1)\n",
        "        \n",
        "    def forward(self, center_words, target_words, coocs, weighting):\n",
        "        center_embeds = self.embedding_v(center_words) # [batch_size, 1, emb_size]\n",
        "        target_embeds = self.embedding_u(target_words) # [batch_size, 1, emb_size]\n",
        "        \n",
        "        center_bias = self.v_bias(center_words).squeeze(1)\n",
        "        target_bias = self.u_bias(target_words).squeeze(1)\n",
        "        \n",
        "        inner_product = target_embeds.bmm(center_embeds.transpose(1, 2)).squeeze(2)\n",
        "        #[batch_size, 1, emb_size] @ [batch_size, emb_size, 1] = [batch_size, 1, 1] = [batch_size, 1]\n",
        "        \n",
        "        #note that coocs already got log\n",
        "        loss = weighting*torch.pow(inner_product +center_bias + target_bias - coocs, 2)\n",
        "        \n",
        "        return torch.sum(loss)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size     = 10 # mini-batch size\n",
        "embedding_size = 2 #so we can later plot\n",
        "model          = GloVe(voc_size, embedding_size)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1000 | cost: 0.040303 | time: 0m 0s\n",
            "Epoch: 2000 | cost: 0.000282 | time: 0m 0s\n",
            "Epoch: 3000 | cost: 0.000000 | time: 0m 0s\n",
            "Epoch: 4000 | cost: 0.000000 | time: 0m 0s\n",
            "Epoch: 5000 | cost: 0.000000 | time: 0m 0s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "# Training\n",
        "num_epochs = 5000\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    start = time.time()\n",
        "    \n",
        "    input_batch, target_batch, cooc_batch, weighting_batch = random_batch(batch_size, corpus, skip_grams, X_ik, weighting_dic)\n",
        "    input_batch  = torch.LongTensor(input_batch)         #[batch_size, 1]\n",
        "    target_batch = torch.LongTensor(target_batch)        #[batch_size, 1]\n",
        "    cooc_batch   = torch.FloatTensor(cooc_batch)         #[batch_size, 1]\n",
        "    weighting_batch = torch.FloatTensor(weighting_batch) #[batch_size, 1]\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss = model(input_batch, target_batch, cooc_batch, weighting_batch)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    epoch_mins, epoch_secs = epoch_time(start, end)\n",
        "\n",
        "    if (epoch + 1) % 1000 == 0:\n",
        "        print(f\"Epoch: {epoch + 1} | cost: {loss:.6f} | time: {epoch_mins}m {epoch_secs}s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Plotting the embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'cat', 'fruit', 'dog', 'banana', 'animal', '<UNK>']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#list of vocabs\n",
        "vocab[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "word = vocab[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#numericalization\n",
        "id = word2index[word]\n",
        "id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_tensor = torch.LongTensor([id])\n",
        "id_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.0399, -0.5737]], grad_fn=<EmbeddingBackward0>),\n",
              " tensor([[1.1545, 0.4224]], grad_fn=<EmbeddingBackward0>))"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#get the embedding by averaging\n",
        "v_embed = model.embedding_v(id_tensor)\n",
        "u_embed = model.embedding_u(id_tensor)\n",
        "\n",
        "v_embed, u_embed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(-0.0757, grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#average to get the word embedding\n",
        "word_embed = (v_embed + u_embed) / 2\n",
        "word_embed[0][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's write a function to get embedding given a word\n",
        "def get_embed(word):\n",
        "    id_tensor = torch.LongTensor([word2index[word]])\n",
        "    v_embed = model.embedding_v(id_tensor)\n",
        "    u_embed = model.embedding_u(id_tensor) \n",
        "    word_embed = (v_embed + u_embed) / 2 \n",
        "    x, y = word_embed[0][0].item(), word_embed[0][1].item()\n",
        "\n",
        "    return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(6,3))\n",
        "for i, word in enumerate(vocab[:20]): #loop each unique vocab\n",
        "    x, y = get_embed(word)\n",
        "    plt.scatter(x, y)\n",
        "    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Cosine similarity\n",
        "\n",
        "Formally the [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity) $s$ between two vectors $p$ and $q$ is defined as:\n",
        "\n",
        "$$s = \\frac{p \\cdot q}{||p|| ||q||}, \\textrm{ where } s \\in [-1, 1] $$ \n",
        "\n",
        "If $p$ and $q$ is super similar, the result is 1 otherwise 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple', 'cat', 'fruit', 'dog', 'banana', 'animal', '<UNK>']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "#let's try similarity between first and second, and second and third\n",
        "cat          = get_embed('cat')\n",
        "fruit        = get_embed('fruit')\n",
        "animal       = get_embed('animal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  -0.39502042509626634\n",
            "cat vs. animal:  0.20299117840966427\n",
            "cat vs. cat:  1.0\n"
          ]
        }
      ],
      "source": [
        "#numpy version\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    return cos_sim\n",
        "    \n",
        "print(f\"cat vs. fruit: \",        cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat vs. fruit:  -0.39502042509626634\n",
            "cat vs. animal:  0.2029911784096643\n",
            "cat vs. cat:  1.0\n"
          ]
        }
      ],
      "source": [
        "#scipy version\n",
        "from scipy import spatial\n",
        "\n",
        "def cos_sim(a, b):\n",
        "    cos_sim = 1 - spatial.distance.cosine(a, b)  #distance = 1 - similarlity, because scipy only gives distance\n",
        "    return cos_sim\n",
        "\n",
        "print(f\"cat vs. fruit: \",     cos_sim(cat, fruit))\n",
        "print(f\"cat vs. animal: \",       cos_sim(cat, animal))\n",
        "print(f\"cat vs. cat: \",          cos_sim(cat, cat))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
